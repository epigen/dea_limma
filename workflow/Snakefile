
##### global workflow dependencies #####
conda: "envs/global.yaml"

##### libraries #####
import os
import sys
import pandas as pd
import yaml
from snakemake.utils import min_version

##### set minimum snakemake version #####
min_version("8.20.1")

module_name = "dea_limma_fz"

##### setup report #####
report: os.path.join("report", "workflow.rst")

##### load config and sample annotation sheets #####
configfile: os.path.join("config", "config.yaml")

# load annotation
annot = pd.read_csv(config['annotation'], index_col='name')
analyses = list(annot.index)
# convert dictionary for parametrization of rules
annot_dict = annot.to_dict('index')
# print(annot_dict)

# load feature list paths and keep only non-empty
feature_lists = []
feature_lists_dict = config["feature_lists"]
feature_lists_dict = {k: v for k, v in feature_lists_dict.items() if v!=""}
if feature_lists_dict is not None:
    feature_lists = feature_lists + list(feature_lists_dict.keys())

result_path = os.path.join(config["result_path"], module_name)

##### load rules #####
include: os.path.join("rules", "common.smk")
include: os.path.join("rules", "dea.smk")
include: os.path.join("rules", "visualize.smk")
include: os.path.join("rules", "envs_export.smk")

##### target rule #####
rule all:
    input:
        results = expand(os.path.join(result_path,'{analysis}','results.csv'),
                            analysis = analyses,
                           ),
        result_feature_lists = expand(os.path.join(result_path, '{analysis}', 'result_feature_lists.txt'),
                            analysis = analyses,
                           ),
        lmfit_objects = expand(os.path.join(result_path,'{analysis}','lmfit_object.rds'),
                            analysis = analyses,
                           ),
        volcanos = expand(os.path.join(result_path,'{analysis}','plots','volcano','{feature_list}'),
                          analysis = analyses,
                          feature_list = feature_lists + ['ALL'],
                         ),
        stats = expand(os.path.join(result_path,'{analysis}','stats.csv'),
                               analysis = analyses,
                      ),
        heatmaps = expand(os.path.join(result_path,'{analysis}','plots','heatmap','{feature_list}.png'),
                          analysis = analyses,
                          feature_list = feature_lists + ['FILTERED'],
                         ),
        envs = expand(os.path.join(result_path,'envs','{env}.yaml'),env=['limma','volcanos','ggplot','heatmap']),
        configs = os.path.join(result_path,'configs','{}_config.yaml'.format(config["project_name"])),
        annotations = os.path.join(result_path,'configs','{}_annot.csv'.format(config["project_name"])),
        feature_lists = expand(os.path.join(result_path,'configs','{feature_list}.txt'), feature_list = feature_lists),
    resources:
        mem_mb=config.get("mem", "16000"),
    threads: config.get("threads", 1)
    log:
        os.path.join("logs","rules","all.log"),

        

