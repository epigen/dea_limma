
##### global workflow dependencies #####
conda: "envs/global.yaml"

##### libraries #####
import os
import sys
import pandas as pd
import yaml
from snakemake.utils import min_version

######## CODE BELOW solves Missing Input Exception when used as input module for e.g., enrichment_analysis BUT requires Snakemake 8
# # Global workflow dependency
# # https://snakemake.readthedocs.io/en/stable/snakefiles/deployment.html#global-workflow-dependencies
# conda:
#     "envs/global.yaml"
# from patsy import dmatrix

# import pandas as pd
# from patsy import dmatrix

# def get_r_style_column_names(formula, file_path, reference_levels=None):
#     # Load the data from the file
#     df = pd.read_csv(file_path)
    
#     # Set reference levels if provided
#     if reference_levels:
#         for var, ref_level in reference_levels.items():
#             if var in df.columns:
#                 levels = list(df[var].unique())
#                 if ref_level in levels:
#                     levels.remove(ref_level)
#                     levels = [ref_level] + levels
#                     df[var] = pd.Categorical(df[var], categories=levels, ordered=True)
    
#     # Create the design matrix
#     X = dmatrix(formula, data=df, return_type='dataframe')
    
#     # Convert to the correct R-style column names
#     def convert_to_r_style(col_name):
#         # Remove brackets and handle interaction terms
#         col_name = col_name.replace('[', '').replace(']', '')
#         col_name = col_name.replace('T.', '')
#         return col_name
    
#     r_style_column_names = [convert_to_r_style(col) for col in X.columns]
    
#     return r_style_column_names

# # Apply the function to the provided data and formula
# file_path = '/mnt/data/annotation (1).csv'
# formula = '0 + celltype + celltype:genotype'
# reference_levels = {
#     'genotype': 'WT'
# }
# r_style_column_names = get_r_style_column_names(formula, file_path, reference_levels)
# print(r_style_column_names)

##### set minimum snakemake version #####
min_version("8.20.1")

module_name = "dea_limma"

##### container image #####
# containerized: "docker://sreichl/..."

##### setup report #####
report: os.path.join("report", "workflow.rst")

##### load config and sample annotation sheets #####
configfile: os.path.join("config", "config.yaml")

# load annotation
annot = pd.read_csv(config['annotation'], index_col='name')
analyses = list(annot.index)
# convert dictionary for parametrization of rules
annot_dict = annot.to_dict('index')
# print(annot_dict)

# load feature list paths and keep only non-empty
feature_lists = []
feature_lists_dict = config["feature_lists"]
feature_lists_dict = {k: v for k, v in feature_lists_dict.items() if v!=""}
if feature_lists_dict is not None:
    feature_lists = feature_lists + list(feature_lists_dict.keys())

result_path = os.path.join(config["result_path"], module_name)

##### load rules #####
include: os.path.join("rules", "common.smk")
include: os.path.join("rules", "dea.smk")
include: os.path.join("rules", "visualize.smk")
include: os.path.join("rules", "envs_export.smk")

##### target rule #####
rule all:
    input:
        results = expand(os.path.join(result_path,'{analysis}','results.csv'),
                            analysis = analyses,
                           ),
        result_feature_lists = expand(os.path.join(result_path, '{analysis}', 'result_feature_lists.txt'),
                            analysis = analyses,
                           ),
        lmfit_objects = expand(os.path.join(result_path,'{analysis}','lmfit_object.rds'),
                            analysis = analyses,
                           ),
        volcanos = expand(os.path.join(result_path,'{analysis}','plots','volcano','{feature_list}'),
                          analysis = analyses,
                          feature_list = feature_lists + ['ALL'],
                         ),
        stats = expand(os.path.join(result_path,'{analysis}','stats.csv'),
                               analysis = analyses,
                      ),
        heatmaps = expand(os.path.join(result_path,'{analysis}','plots','heatmap','{feature_list}.png'),
                          analysis = analyses,
                          feature_list = feature_lists + ['FILTERED'],
                         ),
        envs = expand(os.path.join(result_path,'envs','{env}.yaml'),env=['limma','volcanos','ggplot','heatmap']),
        configs = os.path.join(result_path,'configs','{}_config.yaml'.format(config["project_name"])),
        annotations = os.path.join(result_path,'configs','{}_annot.csv'.format(config["project_name"])),
        feature_lists = expand(os.path.join(result_path,'configs','{feature_list}.txt'), feature_list = feature_lists),
    resources:
        mem_mb=config.get("mem", "16000"),
    threads: config.get("threads", 1)
    log:
        os.path.join("logs","rules","all.log"),

        

